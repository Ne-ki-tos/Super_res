{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "import math\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(target, ref):\n",
    "         \n",
    "    target_data = target.astype(float)\n",
    "    ref_data = ref.astype(float)\n",
    "\n",
    "    diff = ref_data - target_data\n",
    "    diff = diff.flatten('C')\n",
    "\n",
    "    rmse = math.sqrt(np.mean(diff ** 2.))\n",
    "\n",
    "    return 20 * math.log10(255. / (rmse + 0.0000001)) # Избегаем деления на 0\n",
    "\n",
    "# mean squared error (MSE)\n",
    "def mse(target, ref):\n",
    "    err = np.sum((target.astype('float') - ref.astype('float')) ** 2)\n",
    "    err /= float(target.shape[0] * target.shape[1])\n",
    "    \n",
    "    return err\n",
    "\n",
    "# Объединяем все метрики в одну функцию\n",
    "def compare_images(target, ref):\n",
    "    scores = []\n",
    "    scores.append(psnr(target, ref))\n",
    "    scores.append(mse(target, ref))\n",
    "    scores.append(ssim(target, ref, multichannel =True))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef prepare_images(path, factor):\\n    \\n    for file in os.listdir(path):\\n        \\n        img = cv2.imread(path + file)\\n        \\n        h, w, _ = img.shape\\n        new_height = h // factor\\n        new_width = w // factor\\n        \\n        # уменьшаем картинку\\n        img = cv2.resize(img, (new_width, new_height), interpolation = cv2.INTER_LINEAR)\\n        \\n        # растягиваем картинку обратно (обычной интерполяцией), чтобы ухудшить качество\\n        img = cv2.resize(img, (w, h), interpolation = cv2.INTER_LINEAR)\\n        \\n        print('Saving {}'.format(file))\\n        cv2.imwrite('Images/{}'.format(file), img)\\nprepare_images('Source/', 2)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подготавливаем испорченные изображения\n",
    "'''\n",
    "def prepare_images(path, factor):\n",
    "    \n",
    "    for file in os.listdir(path):\n",
    "        \n",
    "        img = cv2.imread(path + file)\n",
    "        \n",
    "        h, w, _ = img.shape\n",
    "        new_height = h // factor\n",
    "        new_width = w // factor\n",
    "        \n",
    "        # уменьшаем картинку\n",
    "        img = cv2.resize(img, (new_width, new_height), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        # растягиваем картинку обратно (обычной интерполяцией), чтобы ухудшить качество\n",
    "        img = cv2.resize(img, (w, h), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        print('Saving {}'.format(file))\n",
    "        cv2.imwrite('Images/{}'.format(file), img)\n",
    "prepare_images('Source/', 2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor file in os.listdir('Images/'):\\n    \\n    # open target and reference images\\n    target = cv2.imread('Images/{}'.format(file))\\n    ref = cv2.imread('Source/{}'.format(file))\\n    \\n    # calculate score\\n    scores = compare_images(target, ref)\\n\\n    # print all three scores with new line characters (\\n) \\n    print('{}\\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(file, scores[0], scores[1], scores[2]))\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for file in os.listdir('Images/'):\n",
    "    \n",
    "    # open target and reference images\n",
    "    target = cv2.imread('Images/{}'.format(file))\n",
    "    ref = cv2.imread('Source/{}'.format(file))\n",
    "    \n",
    "    # calculate score\n",
    "    scores = compare_images(target, ref)\n",
    "\n",
    "    # print all three scores with new line characters (\\n) \n",
    "    print('{}\\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(file, scores[0], scores[1], scores[2]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"Train/\"\n",
    "VAL_PATH = \"Test/Set14/\"\n",
    "TEST_PATH = \"Test/Set5/\"\n",
    "Random_Crop = 30\n",
    "Patch_size = 32\n",
    "label_size = 20\n",
    "conv_side = 6\n",
    "scale = 2\n",
    "\n",
    "# подготавливаем данные\n",
    "\n",
    "def prepare_data(_path):\n",
    "    names = os.listdir(_path)\n",
    "    names = sorted(names)\n",
    "    nums = names.__len__()\n",
    "\n",
    "    data = np.zeros((nums * Random_Crop, 1, Patch_size, Patch_size), dtype=np.double)\n",
    "    label = np.zeros((nums * Random_Crop, 1, label_size, label_size), dtype=np.double)\n",
    "\n",
    "    for i in range(nums):\n",
    "        name = _path + names[i]\n",
    "        hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "        shape = hr_img.shape\n",
    "\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        hr_img = hr_img[:, :, 0]\n",
    "\n",
    "        # растягиваем картинку туда-сюда, чтобы ухудшить качество\n",
    "        lr_img = cv2.resize(hr_img, (shape[1] // scale, shape[0] // scale))\n",
    "        lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "\n",
    "        # Набираем случайно patches для обучения\n",
    "        Points_x = np.random.randint(0, min(shape[0], shape[1]) - Patch_size, Random_Crop)\n",
    "        Points_y = np.random.randint(0, min(shape[0], shape[1]) - Patch_size, Random_Crop)\n",
    "\n",
    "        for j in range(Random_Crop):\n",
    "            lr_patch = lr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "            hr_patch = hr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "\n",
    "            lr_patch = lr_patch.astype(float) / 255.\n",
    "            hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "            data[i * Random_Crop + j, 0, :, :] = lr_patch\n",
    "            label[i * Random_Crop + j, 0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "            # cv2.imshow(\"lr\", lr_patch)\n",
    "            # cv2.imshow(\"hr\", hr_patch)\n",
    "            # cv2.waitKey(0)\n",
    "    return data, label\n",
    "\n",
    "# BORDER_CUT = 8\n",
    "BLOCK_STEP = 16\n",
    "BLOCK_SIZE = 32\n",
    "\n",
    "\n",
    "def prepare_crop_data(_path):\n",
    "    names = os.listdir(_path)\n",
    "    names = sorted(names)\n",
    "    nums = names.__len__()\n",
    "\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for i in range(nums):\n",
    "        name = _path + names[i]\n",
    "        hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        hr_img = hr_img[:, :, 0]\n",
    "        shape = hr_img.shape\n",
    "\n",
    "        # растягиваем картинку туда-сюда, чтобы ухудшить качество\n",
    "        lr_img = cv2.resize(hr_img, (shape[1] // scale, shape[0] // scale))\n",
    "        lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "\n",
    "        width_num = (shape[0] - (BLOCK_SIZE - BLOCK_STEP) * 2) // BLOCK_STEP\n",
    "        height_num = (shape[1] - (BLOCK_SIZE - BLOCK_STEP) * 2) // BLOCK_STEP\n",
    "        for k in range(width_num):\n",
    "            for j in range(height_num):\n",
    "                x = k * BLOCK_STEP\n",
    "                y = j * BLOCK_STEP\n",
    "                hr_patch = hr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "                lr_patch = lr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "\n",
    "                lr_patch = lr_patch.astype(float) / 255.\n",
    "                hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "                lr = np.zeros((1, Patch_size, Patch_size), dtype=np.double)\n",
    "                hr = np.zeros((1, label_size, label_size), dtype=np.double)\n",
    "\n",
    "                lr[0, :, :] = lr_patch\n",
    "                hr[0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "\n",
    "                data.append(lr)\n",
    "                label.append(hr)\n",
    "\n",
    "    data = np.array(data, dtype=float)\n",
    "    label = np.array(label, dtype=float)\n",
    "    return data, label\n",
    "\n",
    "\n",
    "def write_hdf5(data, labels, output_filename):\n",
    "\n",
    "    x = data.astype(np.float32)\n",
    "    y = labels.astype(np.float32)\n",
    "\n",
    "    with h5py.File(output_filename, 'w') as h:\n",
    "        h.create_dataset('data', data=x, shape=x.shape)\n",
    "        h.create_dataset('label', data=y, shape=y.shape)\n",
    "        # h.create_dataset()\n",
    "\n",
    "\n",
    "def read_training_data(file):\n",
    "    with h5py.File(file, 'r') as hf:\n",
    "        data = np.array(hf.get('data'))\n",
    "        label = np.array(hf.get('label'))\n",
    "        train_data = np.transpose(data, (0, 2, 3, 1))\n",
    "        train_label = np.transpose(label, (0, 2, 3, 1))\n",
    "        return train_data, train_label\n",
    "    \n",
    "data, label = prepare_crop_data(DATA_PATH)\n",
    "write_hdf5(data, label, \"train.h5\")\n",
    "data, label = prepare_data(VAL_PATH)\n",
    "write_hdf5(data, label, \"val.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "    SRCNN = Sequential()\n",
    "    \n",
    "    # Делаем три слоя, как в статье\n",
    "    SRCNN.add(Conv2D(filters=128, kernel_size = (9, 9), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))\n",
    "    SRCNN.add(Conv2D(filters=64, kernel_size = (3, 3), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='same', use_bias=True))\n",
    "    SRCNN.add(Conv2D(filters=1, kernel_size = (5, 5), kernel_initializer='glorot_uniform',\n",
    "                     activation='linear', padding='valid', use_bias=True))\n",
    "    \n",
    "    # Оптимизатор будет один на все слои\n",
    "    # И learning rate тоже будет одинаковый\n",
    "    adam = Adam(lr=0.0003)\n",
    "    \n",
    "    SRCNN.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    \n",
    "    return SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def modcrop(img, scale):\n",
    "    tmpsz = img.shape\n",
    "    sz = tmpsz[0:2]\n",
    "    sz = sz - np.mod(sz, scale)\n",
    "    img = img[0:sz[0], 0:sz[1]]\n",
    "    return img\n",
    "'''\n",
    "\n",
    "def degradation(img, scale):\n",
    "    h, w, _ = img.shape\n",
    "    new_height = h // scale\n",
    "    new_width = w // scale\n",
    "        \n",
    "    # сжимаем и растягиваем картинку, чтобы ухудшить качество\n",
    "    img = cv2.resize(img, (new_width, new_height), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "    img = cv2.resize(img, (w, h), interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "# Обрезаем края\n",
    "def shave(image, border):\n",
    "    img = image[border: -border, border: -border]\n",
    "    return img\n",
    "\n",
    "# Тренировочная функция\n",
    "def train():\n",
    "    print(srcnn_model.summary())\n",
    "    data, label = read_training_data(\"train.h5\")\n",
    "    val_data, val_label = read_training_data(\"val.h5\")\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\"SRCNN_check.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                 save_weights_only=False, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    srcnn_model.fit(data, label, batch_size=128, validation_data=(val_data, val_label),\n",
    "                    callbacks=callbacks_list, shuffle=True, epochs=50, verbose=0)\n",
    "\n",
    "# Предсказывающая функция\n",
    "def predict(img):\n",
    "    # img = cv2.imread(image_path)\n",
    "    \n",
    "    \n",
    "    # конвертируем в YCrCb\n",
    "    temp = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # нормализуем \n",
    "    Y = np.zeros((1, temp.shape[0], temp.shape[1], 1), dtype=float)\n",
    "    Y[0, :, :, 0] = temp[:, :, 0].astype(float) / 255\n",
    "    \n",
    "    # применяем модель\n",
    "    pre = srcnn_model.predict(Y, batch_size=1)\n",
    "    \n",
    "    # пост-обработка\n",
    "    pre *= 255\n",
    "    pre[pre[:] > 255] = 255\n",
    "    pre[pre[:] < 0] = 0\n",
    "    pre = pre.astype(np.uint8)\n",
    "    \n",
    "    # конвертируем в BGR\n",
    "    temp = shave(temp, 6)\n",
    "    temp[:, :, 0] = pre[0, :, :, 0]\n",
    "    output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(image_path, scale):\n",
    "\n",
    "    ref = cv2.imread(image_path) # оригинальные данные\n",
    "    degraded = degradation(ref, scale) # испорченные данные\n",
    "    \n",
    "    #ref = modcrop(ref, 3)\n",
    "    #degraded = modcrop(degraded, 3)\n",
    "    \n",
    "    output = predict(degraded) # восстановленные данные\n",
    "\n",
    "    # убираем границу\n",
    "    ref = shave(ref.astype(np.uint8), 6)\n",
    "    degraded = shave(degraded.astype(np.uint8), 6)\n",
    "    \n",
    "    # считам метрики\n",
    "    scores = []\n",
    "    scores.append(compare_images(degraded, ref))\n",
    "    scores.append(compare_images(output, ref))\n",
    "    \n",
    "    return ref, degraded, output, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, None, None, 128)   10496     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 64)    73792     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 1)     1601      \n",
      "=================================================================\n",
      "Total params: 85,889\n",
      "Trainable params: 85,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00211, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00211 to 0.00167, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00167 to 0.00154, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00154\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00154 to 0.00145, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00145 to 0.00143, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00143\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00143 to 0.00139, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00139 to 0.00137, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00137\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00137 to 0.00136, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00136 to 0.00135, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00135 to 0.00135, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00135 to 0.00134, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00134 to 0.00133, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00133\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00133 to 0.00132, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00132\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00132 to 0.00131, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00131\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00131 to 0.00130, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00130\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00130\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00130 to 0.00130, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00130 to 0.00129, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00129\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00129 to 0.00128, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00128\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00128\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00128\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00128\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00128\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00128 to 0.00128, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00128\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00128 to 0.00127, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00127\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00127\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00127 to 0.00127, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00127\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00127 to 0.00126, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00126\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00126\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00126 to 0.00126, saving model to SRCNN_check.h5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00126\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00126\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00126\n"
     ]
    }
   ],
   "source": [
    "srcnn_model = model()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving woman_GT.bmp\n",
      "Saving butterfly_GT.bmp\n",
      "Saving bird_GT.bmp\n",
      "Saving head_GT.bmp\n",
      "Saving baby_GT.bmp\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('Test/Set5'):\n",
    "    \n",
    "    # Проходим по тестовой выборке и сохраняем результаты сравнения оригинальной, испорченной и восстановленной \n",
    "    # картинок между собой\n",
    "    ref, degraded, output, scores = results('Test/Set5/{}'.format(file), 2)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 8))\n",
    "    axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title('Original')\n",
    "    axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
    "    axs[1].set_title('Degraded')\n",
    "    axs[1].set(xlabel = 'PSNR: {}\\nMSE: {} \\nSSIM: {}'.format(scores[0][0], scores[0][1], scores[0][2]))\n",
    "    axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "    axs[2].set_title('SRCNN')\n",
    "    axs[2].set(xlabel = 'PSNR: {} \\nMSE: {} \\nSSIM: {}'.format(scores[1][0], scores[1][1], scores[1][2]))\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "      \n",
    "    print('Saving {}'.format(file))\n",
    "    fig.savefig('Output/{}.png'.format(os.path.splitext(file)[0])) \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь в Output можно посмотреть результаты"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
